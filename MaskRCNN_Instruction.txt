# The INSTRUCTION of training MaskRCNN on custom object.
# IT is writen by T.Q. DENG at 2018/3/31 in CNV.
# This instruction is consisted in two parts. First part creates a conda virtual environment with python 3.6.
# Second part is the instruction of training MaskRCNN on custom object.

## Part I: creates a conda virtual environment with python 3.6

## step1: creates a conda virtual environment with python 3.6
# we use Anaconda with python 3.6. if you don't have Anaconda, please install it. This is a tutorial in Windows platform ref https://www.youtube.com/watch?v=T8wK5loXkXg if in ubuntu, it is more convenient, please refer it https://blog.csdn.net/u012318074/article/details/77074665
# in a new directory Mask/, open the terminal

conda create -n MaskRCNN python=3.6 pip
# after this, we created a virtual envs of directory MaskRCNN/, it will be in location at /home/near/anaconda2/envs/MaskRCNN/.... in this directory, it include a lot of files.

## step2 Install the Dependencies
# in directory Mask/ , place the requirements.txt in directory Mask/ , requirements.txt can be found in this https://github.com/markjay4k/Mask-RCNN-series/blob/master/requirements.txt

source activate MaskRCNN
pip install -r requirements.txt
pip install pyyaml # this will be used in training maskRCNN  below

# it just like this (MaskRCNN) near@server:~/dtq/Mask$
# NOTE: The below step  all in (MaskRCNN) envs.

# NOTE: we're installing these (tf-gpu requires some pre-reqs)
# numpy, scipy, cython, h5py, Pillow, scikit-image,
# tensorflow-gpu==1.4, keras, jupyter         # I modify the version of tensorflow-gpu. now it is 1.4.

## Step3 Clone the Mask RCNN Repo
# in directory Mask/

git clone https://github.com/matterport/Mask_RCNN.git

# after this, you will find directory MaskRCNN/ in directory Mask/

## Step4 Install pycocotools

# in directory Mask/

git clone https://github.com/philferriere/cocoapi.git
# after this, you will find directory cocoapi/ in the directory Mask/

# in directory Mask/ , use pip to install pycocotools
pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI

cd cocoapi/PythonAPI
make

# after make ,you can try whether it installed successfully. Ref https://blog.csdn.net/u011961856/article/details/77676461

## step5 download the pre-trained weights
# here https://github.com/matterport/Mask_RCNN/releases
# download mask_rcnn_coco.h5 file
# in directory Mask/MaskRCNN/
place the file in the Mask_RCNN directory

## step6 test MaskRCNN
# in directory Mask/MaskRCNN/
jupyter notebook
# run demo.ipynb

## part II :  the instruction of training MaskRCNN on custom object.
# ref: https://blog.csdn.net/l297969586/article/details/79140840
# all step  in diretory  MaskRCNN/ , NOTE: The below step  all in (MaskRCNN) envs.

# step1: use labelme to generate mask
# FINAL DIRECTORY is shown IN DIRECTORY net_img/
'''
near@server:~/dtq/Mask/Mask_RCNN/net_img$ tree
.
├── json
│   ├── rgb_1_json
│   │   ├── img.png
│   │   ├── info.yaml
│   │   ├── label_names.txt
│   │   ├── label.png
│   │   └── label_viz.png
│   ├── rgb_2_json
│   │   ├── img.png
│   │   ├── info.yaml
│   │   ├── label_names.txt
│   │   ├── label.png
│   │   └── label_viz.png
│   ├── rgb_3_json
│   │   ├── img.png
│   │   ├── info.yaml
│   │   ├── label_names.txt
│   │   ├── label.png
│   │   └── label_viz.png
│   ├── rgb_4_json
│   │   ├── img.png
│   │   ├── info.yaml
│   │   ├── label_names.txt
│   │   ├── label.png
│   │   └── label_viz.png
│   ├── rgb_5_json
│   │   ├── img.png
│   │   ├── info.yaml
│   │   ├── label_names.txt
│   │   ├── label.png
│   │   └── label_viz.png
│   └── rgb_6_json
│       ├── img.png
│       ├── info.yaml
│       ├── label_names.txt
│       ├── label.png
│       └── label_viz.png
├── mask
│   ├── 1.png
│   ├── 2.png
│   ├── 3.png
│   ├── 4.png
│   ├── 5.png
│   └── 6.png
├── rgb
│   ├── rgb_1.jpg
│   ├── rgb_2.jpg
│   ├── rgb_3.jpg
│   ├── rgb_4.jpg
│   ├── rgb_5.jpg
│   └── rgb_6.jpg
├── rgb_1.json
├── rgb_2.json
├── rgb_3.json
├── rgb_4.json
├── rgb_5.json
└── rgb_6.json

9 directories, 48 files
'''

# in directory MaskRCNN/

mkdir net_img     # the directory net_img/ stores all files with  mask
cd net_img
mkdir rgb        # directory rgb/ stores train images and their jsons generated  directly by labelme, it will include rgb_1.jpg,rgb1.json,rgb_2.jpg,...

sudo apt-get install python-qt4 pyqt4-dev-tools
sudo pip install labelme
labelme

# Note：在画掩码过程中如有多个box、fruit…命名规则为box1、box2..fruit1、fruit2..。因为labelme这个标定工具还是不太智能，最后生成的标签为一个label.png文件，这个文件只有一通道，在你标注时同一标签mask会被给予一个标签位，而mask要求不同的实例要放在不同的层中。最终训练索要得到的输入为一个w*h*n的ndarray，其中n为该图片中实例的个数。总而言之，画mask时就按照上述命名规则就好了.
# after labelme ,you wil find many rgb_x.jpg and thier rgb_x.json in directory rgb/.
# 此时labelme生成的为.json文件，需要将json文件转换为我们需要的标签文件，我这里写了一个简单的脚本，不用一个个去转化了，只需将s1改为你对应的路径及图片前缀名，循环数改为自己数据集数即可

# in diretory net_img/, we put json_to_dataset.sh in here

'''
#!/bin/bash
s1="/home/near/dtq/Mask/Mask_RCNN/net_img/rgb/rgb_"
s2=".json"
for((i=1;i<7;i++)) # total 6 pics
do
s3=${i}
labelme_json_to_dataset ${s1}${s3}${s2}
done
'''
bash json_to_dataset.sh

# after this, you will find many directory rgb_x_json/ in directory rgb/

# we move all this rgb_x_json/ to directory json/
# in directory net_img/
mkdir json
# after move, it stores the lable files we need to train, it will include many rgb_x_json file, in every rgb_x_json file, it will include img.png(orital picture), info.yaml, label.png, label_viz.png, we only need info.yaml, label.png

# labelme生成的掩码标签 label.png为16位存储，opencv默认读取8位，需要将16位转8位
# in directory net_img/
mkdir mask

# in directory net_ing/, we put 16_to_8.cpp in here
'''
#include <iostream>
#include <opencv2/opencv.hpp>
#include <string>
#include <stdio.h>
using namespace std;
using namespace cv;
int main(void){
    char buff1[100];
    char buff2[100];
    for(int i=1;i<7;i++){
        sprintf(buff1,"path-to-root/net_img/json/rgb_%d_json/label.png",i);
        sprintf(buff2,"path-to-root/net-img/mask/%d.png",i);

        Mat src;
        //Mat dst;
        src=imread(buff1,CV_LOAD_IMAGE_UNCHANGED);
        Mat ff=Mat::zeros(src.rows,src.cols,CV_8UC1);
        for(int k=0;k<src.rows;k++){
            for(int kk=0;kk<src.cols;kk++){
                int n=src.at<ushort>(k,kk);
                ff.at<uchar>(k,kk)=n;
            }
        }
        //src.copyTo(dst);
        //imshow("haha",ff*100);
        //waitKey(0);
        imwrite(buff2,ff);
    }
    return 0;
}
'''
# after this, directory mask/ have many x.png， all is 8 bits label png

# finally, we need to move rgb_x.json in directory rgb/ to diretory net_img/, of cource , you can delete rgb_x.json
# because in training phrase, we actually only need rgb_x.jpg in rgb/, info.yaml in json/rgb_x_json/, x.png in mask/.

## step2 modify train_shapes.py
# in directory MaskRCNN/
# copy and rename train_shapes_net.py
import os
import sys
import random
import math
import re
import time
import numpy as np
import cv2
import matplotlib
import matplotlib.pyplot as plt
import yaml                       # add this, modify
from PIL import Image             # add this, modify



from config import Config
import utils
import model as modellib
import visualize
from model import log

#from IPython import get_ipython

#get_ipython().run_line_magic('matplotlib', 'inline')

# Root directory of the project
ROOT_DIR = os.getcwd()

# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, "logs")

# Local path to trained weights file
COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco.h5") # the pre-trained weights
# Download COCO trained weights from Releases if needed
if not os.path.exists(COCO_MODEL_PATH):
    utils.download_trained_weights(COCO_MODEL_PATH)


# ## Configurations

# In[2]:


#
iter_num = 0  # global, modify

class ShapesConfig(Config):
    """Configuration for training on the toy shapes dataset.
    Derives from the base Config class and overrides values specific
    to the toy shapes dataset.
    """
    # Give the configuration a recognizable name
    NAME = "shapes"

    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each
    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).
    GPU_COUNT = 1 #1 modify
    IMAGES_PER_GPU = 1 #8

    # Number of classes (including background)
    NUM_CLASSES = 1 + 1  # background + 3 shapes , modify

    # Use small images for faster training. Set the limits of the small side
    # the large side, and that determines the image shape.
    IMAGE_MIN_DIM = 379 #128,hight, modify
    IMAGE_MAX_DIM = 448 #128, width, modify

    # Use smaller anchors because our image and objects are small
    RPN_ANCHOR_SCALES = (8 * 2, 16 * 2, 32 * 2, 64 * 2, 128 * 2)  # anchor side in pixels
    # modify
    # Reduce training ROIs per image because the images are small and have
    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.
    TRAIN_ROIS_PER_IMAGE = 32

    # Use a small epoch since the data is simple
    STEPS_PER_EPOCH = 20000#100  # modify

    # use small validation steps since the epoch is small
    VALIDATION_STEPS = 5

config = ShapesConfig()
config.display()



# ## Notebook Preferences

# In[3]:


def get_ax(rows=1, cols=1, size=8):
    """Return a Matplotlib Axes array to be used in
    all visualizations in the notebook. Provide a
    central point to control graph sizes.

    Change the default size attribute to control the size
    of rendered images
    """
    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))
    return ax


# ## Dataset
#
# Create a synthetic dataset
#
# Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:
#
# * load_image()
# * load_mask()
# * image_reference()

# In[4]:
# modify
class DrugDataset(utils.Dataset):
    #得到该图中有多少个实例（物体
    def get_obj_index(self, image):
        n = np.max(image)
        return n
#解析labelme中得到的yaml文件，从而得到mask每一层对应的实例标签
    def from_yaml_get_class(self,image_id):
        info = self.image_info[image_id]
        with open(info['yaml_path']) as f:
            temp=yaml.load(f.read())
            labels=temp['label_names']
            del labels[0]
        return labels

    def draw_mask(self, num_obj, mask, image,image_id):
        info = self.image_info[image_id]
        for index in range(num_obj):
            for i in range(info['width']):
                for j in range(info['height']):
                    at_pixel = image.getpixel((i, j))
                    if at_pixel == index + 1:
                        mask[j, i, index] =1
        return mask

#重新写load_shapes，里面包含自己的自己的类别（我的是box、column、package、fruit四类）
#并在self.image_info信息中添加了path、mask_path 、yaml_path
    def load_shapes(self, count, height, width, img_floder, mask_floder, imglist,dataset_root_path):
        self.add_class("shapes", 1, "bad")
        #self.add_class("shapes", 1, "box")
        #self.add_class("shapes", 2, "column")
        #self.add_class("shapes", 3, "package")
        #self.add_class("shapes", 4, "fruit")
        for i in range(count):
            filestr = imglist[i].split(".")[0]
            filestr = filestr.split("_")[1]
            mask_path = mask_floder + "/" + filestr + ".png"
            yaml_path=dataset_root_path+"json/rgb_"+filestr+"_json/info.yaml"
            self.add_image("shapes", image_id=i, path=img_floder + "/" + imglist[i],
                           width=width, height=height, mask_path=mask_path,yaml_path=yaml_path)

    def load_mask(self, image_id):
        global iter_num
        info = self.image_info[image_id]
        count = 1  # number of object
        img = Image.open(info['mask_path'])
        num_obj = self.get_obj_index(img)
        mask = np.zeros([info['height'], info['width'], num_obj], dtype=np.uint8)
        mask = self.draw_mask(num_obj, mask, img, image_id)
        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)
        for i in range(count - 2, -1, -1):
            mask[:, :, i] = mask[:, :, i] * occlusion
            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))
        labels=[]
        labels=self.from_yaml_get_class(image_id)
        labels_form=[]
        for i in range(len(labels)):
            if labels[i].find("bad")!=-1: # if you have more class, please modify it
                #print "box"
                labels_form.append("bad")
            # elif labels[i].find("column")!=-1:
            #     #print "column"
            #     labels_form.append("column")
            # elif labels[i].find("package")!=-1:
            #     #print "package"
            #     labels_form.append("package")
            # elif labels[i].find("fruit")!=-1:
            #     #print "fruit"
            #     labels_form.append("fruit")
        class_ids = np.array([self.class_names.index(s) for s in labels_form])
        return mask, class_ids.astype(np.int32)



#基础设置
dataset_root_path= "/home/near/dtq/Mask/Mask_RCNN/net_img/"
img_floder = dataset_root_path+"rgb"
mask_floder = dataset_root_path+"mask"
#yaml_floder = dataset_root_path
imglist = os.listdir(img_floder)
count = len(imglist)
width = 448
height = 379

#train与val数据集准备
dataset_train = DrugDataset()
dataset_train.load_shapes(count, 379, 448, img_floder, mask_floder, imglist,dataset_root_path)
dataset_train.prepare()

dataset_val = DrugDataset()
dataset_val.load_shapes(count, 379, 448, img_floder, mask_floder, imglist,dataset_root_path)
dataset_val.prepare()


# class ShapesDataset(utils.Dataset):
#     """Generates the shapes synthetic dataset. The dataset consists of simple
#     shapes (triangles, squares, circles) placed randomly on a blank surface.
#     The images are generated on the fly. No file access required.
#     """

#     def load_shapes(self, count, height, width):
#         """Generate the requested number of synthetic images.
#         count: number of images to generate.
#         height, width: the size of the generated images.
#         """
#         # Add classes
#         self.add_class("shapes", 1, "square")
#         self.add_class("shapes", 2, "circle")
#         self.add_class("shapes", 3, "triangle")

#         # Add images
#         # Generate random specifications of images (i.e. color and
#         # list of shapes sizes and locations). This is more compact than
#         # actual images. Images are generated on the fly in load_image().
#         for i in range(count):
#             bg_color, shapes = self.random_image(height, width)
#             self.add_image("shapes", image_id=i, path=None,
#                            width=width, height=height,
#                            bg_color=bg_color, shapes=shapes)

#     def load_image(self, image_id):
#         """Generate an image from the specs of the given image ID.
#         Typically this function loads the image from a file, but
#         in this case it generates the image on the fly from the
#         specs in image_info.
#         """
#         info = self.image_info[image_id]
#         bg_color = np.array(info['bg_color']).reshape([1, 1, 3])
#         image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)
#         image = image * bg_color.astype(np.uint8)
#         for shape, color, dims in info['shapes']:
#             image = self.draw_shape(image, shape, dims, color)
#         return image

#     def image_reference(self, image_id):
#         """Return the shapes data of the image."""
#         info = self.image_info[image_id]
#         if info["source"] == "shapes":
#             return info["shapes"]
#         else:
#             super(self.__class__).image_reference(self, image_id)

#     def load_mask(self, image_id):
#         """Generate instance masks for shapes of the given image ID.
#         """
#         info = self.image_info[image_id]
#         shapes = info['shapes']
#         count = len(shapes)
#         mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)
#         for i, (shape, _, dims) in enumerate(info['shapes']):
#             mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),
#                                                 shape, dims, 1)
#         # Handle occlusions
#         occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)
#         for i in range(count-2, -1, -1):
#             mask[:, :, i] = mask[:, :, i] * occlusion
#             occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))
#         # Map class names to class IDs.
#         class_ids = np.array([self.class_names.index(s[0]) for s in shapes])
#         return mask, class_ids.astype(np.int32)

#     def draw_shape(self, image, shape, dims, color):
#         """Draws a shape from the given specs."""
#         # Get the center x, y and the size s
#         x, y, s = dims
#         if shape == 'square':
#             cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)
#         elif shape == "circle":
#             cv2.circle(image, (x, y), s, color, -1)
#         elif shape == "triangle":
#             points = np.array([[(x, y-s),
#                                 (x-s/math.sin(math.radians(60)), y+s),
#                                 (x+s/math.sin(math.radians(60)), y+s),
#                                 ]], dtype=np.int32)
#             cv2.fillPoly(image, points, color)
#         return image

#     def random_shape(self, height, width):
#         """Generates specifications of a random shape that lies within
#         the given height and width boundaries.
#         Returns a tuple of three valus:
#         * The shape name (square, circle, ...)
#         * Shape color: a tuple of 3 values, RGB.
#         * Shape dimensions: A tuple of values that define the shape size
#                             and location. Differs per shape type.
#         """
#         # Shape
#         shape = random.choice(["square", "circle", "triangle"])
#         # Color
#         color = tuple([random.randint(0, 255) for _ in range(3)])
#         # Center x, y
#         buffer = 20
#         y = random.randint(buffer, height - buffer - 1)
#         x = random.randint(buffer, width - buffer - 1)
#         # Size
#         s = random.randint(buffer, height//4)
#         return shape, color, (x, y, s)

#     def random_image(self, height, width):
#         """Creates random specifications of an image with multiple shapes.
#         Returns the background color of the image and a list of shape
#         specifications that can be used to draw the image.
#         """
#         # Pick random background color
#         bg_color = np.array([random.randint(0, 255) for _ in range(3)])
#         # Generate a few random shapes and record their
#         # bounding boxes
#         shapes = []
#         boxes = []
#         N = random.randint(1, 4)
#         for _ in range(N):
#             shape, color, dims = self.random_shape(height, width)
#             shapes.append((shape, color, dims))
#             x, y, s = dims
#             boxes.append([y-s, x-s, y+s, x+s])
#         # Apply non-max suppression wit 0.3 threshold to avoid
#         # shapes covering each other
#         keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)
#         shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]
#         return bg_color, shapes


# In[5]:


# # Training dataset
# dataset_train = ShapesDataset()
# dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])
# dataset_train.prepare()

# # Validation dataset
# dataset_val = ShapesDataset()
# dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])
# dataset_val.prepare()


# In[6]:

# #train与val数据集准备
# dataset_train = DrugDataset()
# dataset_train.load_shapes(count, 379, 448, img_floder, mask_floder, imglist,dataset_root_path)
# dataset_train.prepare()

# dataset_val = DrugDataset()
# dataset_val.load_shapes(count, 379, 448, img_floder, mask_floder, imglist,dataset_root_path)
# dataset_val.prepare()



# Load and display random samples
# image_ids = np.random.choice(dataset_train.image_ids, 4)
# for image_id in image_ids:
#     image = dataset_train.load_image(image_id)
#     mask, class_ids = dataset_train.load_mask(image_id)
#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)


# ## Ceate Model

# In[ ]:


# Create model in training mode
model = modellib.MaskRCNN(mode="training", config=config,
                          model_dir=MODEL_DIR)


# In[7]:


# Which weights to start with?
init_with = "coco"  # imagenet, coco, or last

if init_with == "imagenet":
    model.load_weights(model.get_imagenet_weights(), by_name=True)
elif init_with == "coco":
    # Load weights trained on MS COCO, but skip layers that
    # are different due to the different number of classes
    # See README for instructions to download the COCO weights
    model.load_weights(COCO_MODEL_PATH, by_name=True,
                       exclude=["mrcnn_class_logits", "mrcnn_bbox_fc",
                                "mrcnn_bbox", "mrcnn_mask"])
elif init_with == "last":
    # Load the last model you trained and continue training
    model.load_weights(model.find_last()[1], by_name=True)


# ## Training
#
# Train in two stages:
# 1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.
#
# 2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers="all` to train all layers.

# In[8]:


# Train the head branches
# Passing layers="heads" freezes all layers except the head
# layers. You can also pass a regular expression to select
# which layers to train by name pattern.
model.train(dataset_train, dataset_val,
            learning_rate=config.LEARNING_RATE,
            epochs=1,
            layers='heads')


# In[9]:


# Fine tune all layers
# Passing layers="all" trains all layers. You can also
# pass a regular expression to select which layers to
# train by name pattern.
# model.train(dataset_train, dataset_val,
#             learning_rate=config.LEARNING_RATE / 10,
#             epochs=2,
#             layers="all")


# In[10]:


# Save weights
# Typically not needed because callbacks save after every epoch
# Uncomment to save manually
# model_path = os.path.join(MODEL_DIR, "mask_rcnn_shapes.h5")
# model.keras_model.save_weights(model_path)


# ## Detection

# In[11]:


# class InferenceConfig(ShapesConfig):
#     GPU_COUNT = 1
#     IMAGES_PER_GPU = 1

# inference_config = InferenceConfig()

# # Recreate the model in inference mode
# model = modellib.MaskRCNN(mode="inference",
#                           config=inference_config,
#                           model_dir=MODEL_DIR)

# # Get path to saved weights
# # Either set a specific path or find last trained weights
# # model_path = os.path.join(ROOT_DIR, ".h5 file name here")
# model_path = model.find_last()[1]

# # Load trained weights (fill in path to trained weights here)
# assert model_path != "", "Provide path to trained weights"
# print("Loading weights from ", model_path)
# model.load_weights(model_path, by_name=True)


# # In[12]:


# # Test on a random image
# image_id = random.choice(dataset_val.image_ids)
# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =    modellib.load_image_gt(dataset_val, inference_config,
#                            image_id, use_mini_mask=False)

# log("original_image", original_image)
# log("image_meta", image_meta)
# log("gt_class_id", gt_class_id)
# log("gt_bbox", gt_bbox)
# log("gt_mask", gt_mask)

# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,
#                             dataset_train.class_names, figsize=(8, 8))


# # In[13]:


# results = model.detect([original_image], verbose=1)

# r = results[0]
# visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],
#                             dataset_val.class_names, r['scores'], ax=get_ax())


# # ## Evaluation

# # In[14]:


# # Compute VOC-Style mAP @ IoU=0.5
# # Running on 10 images. Increase for better accuracy.
# image_ids = np.random.choice(dataset_val.image_ids, 10)
# APs = []
# for image_id in image_ids:
#     # Load image and ground truth data
#     image, image_meta, gt_class_id, gt_bbox, gt_mask =        modellib.load_image_gt(dataset_val, inference_config,
#                                image_id, use_mini_mask=False)
#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)
#     # Run object detection
#     results = model.detect([image], verbose=0)
#     r = results[0]
#     # Compute AP
#     AP, precisions, recalls, overlaps =        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,
#                          r["rois"], r["class_ids"], r["scores"], r['masks'])
#     APs.append(AP)

# print("mAP: ", np.mean(APs))

# in directory MaskRCNN/
python train_shapes_net.py
## step3 evaluate the model
# in directory MaskRCNN/
jupyter notebook

# 1、MODIFY THE model PATH
# 2.COPY THE CONFIG IN  train_shapes_net.py to demo_mrcnn.py
# 3.modify the class_names ['BG', 'bad']

run demo_mrcnn.ipynb
